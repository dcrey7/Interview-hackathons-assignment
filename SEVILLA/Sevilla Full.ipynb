{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from os import listdir\n",
    "from re import findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.zip\")\n",
    "test = pd.read_csv(\"test.zip\")\n",
    "test_init = test[['row_id']].copy()\n",
    "\n",
    "def check_test(test):\n",
    "    return len(test[['row_id']].merge(test_init, on = 'row_id')) == len(test_init) and \\\n",
    "           len(test) == len(test_init)\n",
    "\n",
    "winner_dict = {'winner' : 3, 'draw' : 1, 'loser' : 0}\n",
    "\n",
    "get_dict = lambda df, team, ren_team: dict([x, x.replace(team, ren_team)] for x in df.columns if team in x)\n",
    "\n",
    "def preprocess_df(df):\n",
    "\n",
    "    df['points'] = df['winner'].apply(lambda x: winner_dict[x]).astype('uint8')\n",
    "    df['team'] = df['team'].fillna(\"team1\")\n",
    "    df['is_home'] = (df['team'] == 'team1').astype('uint8')\n",
    "    df['player_bmi'] = df['player_weight'] / (df['player_weight'] ** 2)\n",
    "    df['changed_position'] = (df['player_position_1'] != df['player_position_2']).astype('uint8')\n",
    "    df_fillna = df.median()\n",
    "    df = df.fillna(df_fillna)\n",
    "    \n",
    "    for c in [x for x in df.columns if 'team1' in x and 'system_id' not in x]:\n",
    "        df[c.replace(\"team1\", \"diff\")] = df[c] - df[c.replace('team1', 'team2')]\n",
    "    \n",
    "    return df\n",
    "\n",
    "full_df = train.drop(columns = ['rating_num']).append(test, ignore_index = True)\n",
    "\n",
    "full_df = preprocess_df(full_df)\n",
    "check_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features = full_df.isna().mean().sort_values() == 1\n",
    "bad_features = bad_features[bad_features].index.tolist() + ['player_other_ratio_var_7']\n",
    "permanent_features = (full_df.std() / full_df.median()).abs() < 0.1\n",
    "permanent_features = permanent_features[permanent_features].index.tolist()\n",
    "\n",
    "full_df.drop(columns = bad_features + permanent_features, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20453, 918), (8774, 918))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['row_id', 'rating_num']].merge(full_df)\n",
    "test = test[['row_id']].merge(full_df)\n",
    "\n",
    "check_test(test)\n",
    "\n",
    "X_train = train.drop(columns = ['rating_num', 'row_id', 'winner', 'team', 'player_position_2']).copy()\n",
    "y_train = train['rating_num'].copy()\n",
    "\n",
    "X_test = test.drop(columns = ['row_id', 'winner', 'team', 'player_position_2']).copy()\n",
    "\n",
    "X_fillna = X_train.median()\n",
    "X_train = X_train.fillna(X_fillna)\n",
    "X_test = X_test.fillna(X_fillna)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['scout_id', 'competitionId', 'player_position_1', 'team1_system_id', 'team2_system_id', 'is_home']\n",
    "\n",
    "model = CatBoostRegressor(cat_features=cat_features, n_estimators=20000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = test[['row_id']]\n",
    "subm['rating_num'] = model.predict(X_test)\n",
    "\n",
    "subm['rating_num'] = (subm['rating_num']).apply(lambda x: min(x, 10))\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test_36.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['player', 'team1', 'team2']:\n",
    "    cur_feats = [x for x in full_df.columns if name in x and 'raw' in x]\n",
    "    for attr in set(x.split(\"_\")[1] for x in cur_feats):\n",
    "        cur_attr_feats = [x for x in cur_feats if attr in x]\n",
    "        full_df[f\"{name}_{attr}_raw_total\"] = full_df[cur_attr_feats].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29227, 1033)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pca_features(feats, name):\n",
    "    global full_df\n",
    "    for c in feats:\n",
    "        full_df[c] = StandardScaler().fit_transform(full_df[c].values.reshape(-1, 1))\n",
    "    \n",
    "    fillna_s = full_df[feats].median()\n",
    "    to_del_cols = fillna_s[fillna_s.isna()].index.tolist()\n",
    "    full_df.drop(columns = to_del_cols, inplace = True)\n",
    "    feats = [x for x in feats if x not in to_del_cols]\n",
    "    full_df = full_df.fillna(fillna_s)\n",
    "    pca = PCA().fit(full_df[feats])\n",
    "    n_components = sum(pca.explained_variance_ratio_.cumsum() <= 0.7)\n",
    "    new_feats = pca.transform(full_df[feats])[:, :n_components].T\n",
    "    for i, c in enumerate(new_feats):\n",
    "        full_df[name+str(i).zfill(2)] = c\n",
    "\n",
    "pca_features([x for x in full_df.columns if 'player' in x and 'position_' not in x], 'player_feature_')\n",
    "pca_features([x for x in full_df.columns if 'diff' in x], 'diff_feature_')\n",
    "pca_features([x for x in full_df.columns if 'team1' in x and 'system_id' not in x], 'team1_feature_')\n",
    "pca_features([x for x in full_df.columns if 'team2' in x and 'system_id' not in x], 'team2_feature_')\n",
    "\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20453, 1029), (8774, 1029))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[['row_id', 'rating_num']].merge(full_df)\n",
    "test = test[['row_id']].merge(full_df)\n",
    "\n",
    "X_train = train.drop(columns = ['rating_num', 'row_id', 'winner', 'team', 'player_position_2']).copy()\n",
    "y_train = train['rating_num'].copy()\n",
    "\n",
    "X_test = test.drop(columns = ['row_id', 'winner', 'team', 'player_position_2']).copy()\n",
    "\n",
    "X_fillna = X_train.median()\n",
    "X_train = X_train.fillna(X_fillna)\n",
    "X_test = X_test.fillna(X_fillna)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['scout_id', 'competitionId', 'player_position_1', 'team1_system_id', 'team2_system_id', 'is_home']\n",
    "\n",
    "model = CatBoostRegressor(cat_features=cat_features, n_estimators=20000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = test[['row_id']]\n",
    "subm['rating_num'] = model.predict(X_test)\n",
    "\n",
    "subm['rating_num'] = (subm['rating_num']).apply(lambda x: min(x, 10))\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test_40.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['scout_id', 'competitionId', 'player_position_1', 'team1_system_id', 'team2_system_id', 'is_home']\n",
    "\n",
    "model_nd = CatBoostRegressor(cat_features=cat_features, n_estimators=20000, random_state=42, max_depth = 4)\n",
    "model_nd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = test[['row_id']]\n",
    "subm['rating_num'] = model_nd.predict(X_test)\n",
    "\n",
    "subm['rating_num'] = (subm['rating_num']).apply(lambda x: min(x, 10))\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test_51.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(max_iter = 1000, C = 5, degree = 4).fit(X_train, y_train)\n",
    "\n",
    "subm = test[['row_id']]\n",
    "subm['rating_num'] = svr.predict(X_test)\n",
    "\n",
    "subm['rating_num'] = (subm['rating_num']).apply(lambda x: max(0, min(x, 10)))\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test_60.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = BayesianRidge(n_iter=1000, normalize=True)\n",
    "bayes.fit(X_train, y_train)\n",
    "\n",
    "subm = test[['row_id']]\n",
    "subm['rating_num'] = bayes.predict(X_test)\n",
    "\n",
    "subm['rating_num'] = (subm['rating_num']).apply(lambda x: max(0, min(x, 10)))\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test_52.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm1 = pd.read_csv(\"submission_test_36.csv\").set_index('row_id').rename(columns = {'rating_num' : 'rating1'}) * 0.45\n",
    "subm2 = pd.read_csv(\"submission_test_40.csv\").set_index('row_id').rename(columns = {'rating_num' : 'rating2'}) * 0.31\n",
    "subm3 = pd.read_csv(\"submission_test_51.csv\").set_index('row_id').rename(columns = {'rating_num' : 'rating3'}) * 0.08\n",
    "subm4 = pd.read_csv(\"submission_test_52.csv\").set_index('row_id').rename(columns = {'rating_num' : 'rating4'}) * 0.08\n",
    "subm5 = pd.read_csv(\"submission_test_60.csv\").set_index('row_id').rename(columns = {'rating_num' : 'rating5'}) * 0.08\n",
    "\n",
    "subm = subm1.join(subm2).join(subm3).join(subm4).join(subm5)\n",
    "subm['rating_num'] = subm.sum(axis = 1).max()\n",
    "subm = subm.reset_index()[['row_id', 'rating_num']]\n",
    "\n",
    "subm['rating_num'] = (10 * (subm['rating_num'] - subm['rating_num'].min()) /\\\n",
    "                        (subm['rating_num'].max() - subm['rating_num'].min())).round(3)\n",
    "\n",
    "if check_test(subm):\n",
    "    subm.to_csv(f\"submission_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
